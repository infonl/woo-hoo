# LLM API Key (used for whichever provider is selected)
# OpenRouter: get key at https://openrouter.ai/keys
# Anthropic: get key at https://console.anthropic.com/
# Custom: depends on your provider (omit for no auth, e.g. local Ollama)
LLM_API_KEY=your-api-key-here

# LLM Provider: 'openrouter' (default), 'anthropic', or 'custom'
LLM_PROVIDER=openrouter

# LLM Model (EU-based Mistral recommended for Dutch government data sovereignty)
DEFAULT_MODEL=mistralai/mistral-large-2512
FALLBACK_MODEL=mistralai/mistral-small-3.2-24b-instruct-2506

# Application
APP_NAME=woo-hoo
APP_URL=http://localhost:8000
DEBUG=false

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=console  # Use 'json' for production

# LLM Settings
MAX_TEXT_LENGTH=15000
LLM_TEMPERATURE=0.1
LLM_TIMEOUT_SECONDS=60
LLM_MAX_RETRIES=3

# For Anthropic direct API (when LLM_PROVIDER=anthropic)
ANTHROPIC_BASE_URL=https://api.anthropic.com

# For custom LLM provider (when LLM_PROVIDER=custom)
# Examples: http://ollama:11434/v1, http://localhost:8000/v1
CUSTOM_LLM_BASE_URL=

# Optional: GPP Integration
# GPP_PUBLICATIEBANK_URL=http://localhost:8080
# GPP_API_TOKEN=your-token-here
